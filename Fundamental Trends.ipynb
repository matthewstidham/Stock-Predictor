{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import stockstats as StockDataFrame\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "plt.rc(\"figure\", figsize=(9, 7))\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import least_squares\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://www.quandl.com/product/WIKIP/WIKI/PRICES-Quandl-End-Of-Day-Stocks-Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright (c) 2016, Cedric Zhuang\n",
    "# All rights reserved.\n",
    "# Redistribution and use in source and binary forms, with or without\n",
    "# modification, are permitted provided that the following conditions are met:\n",
    "#\n",
    "#     * Redistributions of source code must retain the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer.\n",
    "#     * Redistributions in binary form must reproduce the above copyright\n",
    "#       notice, this list of conditions and the following disclaimer in the\n",
    "#       documentation and/or other materials provided with the distribution.\n",
    "#     * Neither the name of disclaimer nor the names of its contributors may\n",
    "#       be used to endorse or promote products derived from this software\n",
    "#       without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS \"AS IS\" AND ANY\n",
    "# EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "# DISCLAIMED. IN NO EVENT SHALL THE REGENTS AND CONTRIBUTORS BE LIABLE FOR ANY\n",
    "# DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "# (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;\n",
    "# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND\n",
    "# ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\n",
    "# (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n",
    "# SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from int_date import get_date_from_diff\n",
    "\n",
    "__author__ = 'Cedric Zhuang'\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class StockDataFrame(pd.DataFrame):\n",
    "    OPERATORS = ['le', 'ge', 'lt', 'gt', 'eq', 'ne']\n",
    "\n",
    "    KDJ_PARAM = (2.0 / 3.0, 1.0 / 3.0)\n",
    "\n",
    "    BOLL_PERIOD = 20\n",
    "    BOLL_STD_TIMES = 2\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_change(df):\n",
    "        df['change'] = df['close'].pct_change() * 100\n",
    "        return df['change']\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_p(df, column, shifts):\n",
    "        \"\"\" get the permutation of specified range\n",
    "\n",
    "        example:\n",
    "        index    x   x_-2,-1_p\n",
    "        0        1         NaN\n",
    "        1       -1         NaN\n",
    "        2        3           2  (0.x > 0, and assigned to weight 2)\n",
    "        3        5           1  (2.x > 0, and assigned to weight 1)\n",
    "        4        1           3\n",
    "\n",
    "        :param df: data frame\n",
    "        :param column: the column to calculate p from\n",
    "        :param shifts: the range to consider\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        column_name = '{}_{}_p'.format(column, shifts)\n",
    "        # initialize the column if not\n",
    "        df.get(column)\n",
    "        shifts = StockDataFrame.to_ints(shifts)[::-1]\n",
    "        indices = None\n",
    "        count = 0\n",
    "        for shift in shifts:\n",
    "            shifted = df.shift(-shift)\n",
    "            index = (shifted[column] > 0) * (2 ** count)\n",
    "            if indices is None:\n",
    "                indices = index\n",
    "            else:\n",
    "                indices += index\n",
    "            count += 1\n",
    "        StockDataFrame.set_nan(indices, shifts)\n",
    "        df[column_name] = indices\n",
    "\n",
    "    @classmethod\n",
    "    def to_ints(cls, shifts):\n",
    "        items = map(cls._process_shifts_segment,\n",
    "                    shifts.split(','))\n",
    "        return sorted(list(set(itertools.chain(*items))))\n",
    "\n",
    "    @classmethod\n",
    "    def to_int(cls, shifts):\n",
    "        numbers = cls.to_ints(shifts)\n",
    "        if len(numbers) != 1:\n",
    "            raise IndexError(\"only accept 1 number.\")\n",
    "        return numbers[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def to_floats(shifts):\n",
    "        floats = map(float, shifts.split(','))\n",
    "        return sorted(list(set(floats)))\n",
    "\n",
    "    @classmethod\n",
    "    def to_float(cls, shifts):\n",
    "        floats = cls.to_floats(shifts)\n",
    "        if len(floats) != 1:\n",
    "            raise IndexError('only accept 1 float.')\n",
    "        return floats[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_shifts_segment(shift_segment):\n",
    "        if '~' in shift_segment:\n",
    "            start, end = shift_segment.split('~')\n",
    "            shifts = range(int(start), int(end) + 1)\n",
    "        else:\n",
    "            shifts = [int(shift_segment)]\n",
    "        return shifts\n",
    "\n",
    "    @staticmethod\n",
    "    def set_nan(pd_obj, shift):\n",
    "        try:\n",
    "            iter(shift)\n",
    "            max_shift = max(shift)\n",
    "            min_shift = min(shift)\n",
    "            StockDataFrame._set_nan_of_single_shift(pd_obj, max_shift)\n",
    "            StockDataFrame._set_nan_of_single_shift(pd_obj, min_shift)\n",
    "        except TypeError:\n",
    "            # shift is not iterable\n",
    "            StockDataFrame._set_nan_of_single_shift(pd_obj, shift)\n",
    "\n",
    "    @staticmethod\n",
    "    def _set_nan_of_single_shift(pd_obj, shift):\n",
    "        val = np.nan\n",
    "        if shift > 0:\n",
    "            pd_obj.iloc[-shift:] = val\n",
    "        elif shift < 0:\n",
    "            pd_obj.iloc[:-shift] = val\n",
    "\n",
    "    @classmethod\n",
    "    def _get_r(cls, df, column, shifts):\n",
    "        \"\"\" Get rate of change of column\n",
    "\n",
    "        :param df: DataFrame object\n",
    "        :param column: column name of the rate to calculate\n",
    "        :param shifts: days to shift, accept one shift only\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        shift = cls.to_int(shifts)\n",
    "        rate_key = '{}_{}_r'.format(column, shift)\n",
    "        df[rate_key] = df[column].pct_change(periods=-shift) * 100\n",
    "\n",
    "    @classmethod\n",
    "    def _get_s(cls, df, column, shifts):\n",
    "        \"\"\" Get the column shifted by days\n",
    "\n",
    "        :param df: DataFrame object\n",
    "        :param column: name of the column to shift\n",
    "        :param shifts: days to shift, accept one shift only\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        shift = cls.to_int(shifts)\n",
    "        shifted_key = \"{}_{}_s\".format(column, shift)\n",
    "        df[shifted_key] = df[column].shift(-shift)\n",
    "        StockDataFrame.set_nan(df[shifted_key], shift)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_log_ret(cls, df):\n",
    "        df['log-ret'] = np.log(df['close'] / df['close_-1_s'])\n",
    "\n",
    "    @classmethod\n",
    "    def _get_c(cls, df, column, shifts):\n",
    "        \"\"\" get the count of column in range (shifts)\n",
    "\n",
    "        example: kdjj_0_le_20_c\n",
    "        :param df: stock data\n",
    "        :param column: column name\n",
    "        :param shifts: range to count, only to previous\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        column_name = '{}_{}_{}'.format(column, shifts, 'c')\n",
    "        shifts = abs(cls.to_int(shifts))\n",
    "        df[column_name] = df[column].rolling(\n",
    "            center=False, window=shifts).apply(np.count_nonzero)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_op(cls, df, column, threshold, op):\n",
    "        column_name = '{}_{}_{}'.format(column, threshold, op)\n",
    "        threshold = cls.to_float(threshold)\n",
    "        f = getattr(operator, op)\n",
    "        df[column_name] = f(df[column], threshold)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_diff_convolve_array(shift):\n",
    "        if shift == 0:\n",
    "            ret = [1]\n",
    "        else:\n",
    "            ret = np.zeros(abs(shift) + 1)\n",
    "            if shift < 0:\n",
    "                ret[[0, -1]] = 1, -1\n",
    "            else:\n",
    "                ret[[0, -1]] = -1, 1\n",
    "        return ret\n",
    "\n",
    "    @classmethod\n",
    "    def _init_shifted_columns(cls, column, df, shifts):\n",
    "        # initialize the column if not\n",
    "        df.get(column)\n",
    "        shifts = cls.to_ints(shifts)\n",
    "        shift_column_names = ['{}_{}_s'.format(column, shift) for shift in\n",
    "                              shifts]\n",
    "        [df.get(name) for name in shift_column_names]\n",
    "        return shift_column_names\n",
    "\n",
    "    @classmethod\n",
    "    def _get_max(cls, df, column, shifts):\n",
    "        column_name = '{}_{}_max'.format(column, shifts)\n",
    "        shift_column_names = cls._init_shifted_columns(column, df, shifts)\n",
    "        df[column_name] = np.max(df[shift_column_names], axis=1)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_min(cls, df, column, shifts):\n",
    "        column_name = '{}_{}_min'.format(column, shifts)\n",
    "        shift_column_names = cls._init_shifted_columns(column, df, shifts)\n",
    "        df[column_name] = np.min(df[shift_column_names], axis=1)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_rsv(df, n_days):\n",
    "        \"\"\" Calculate the RSV (Raw Stochastic Value) within N days\n",
    "\n",
    "        This value is essential for calculating KDJs\n",
    "        Current day is included in N\n",
    "        :param df: data\n",
    "        :param n_days: N days\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        n_days = int(n_days)\n",
    "        column_name = 'rsv_{}'.format(n_days)\n",
    "        low_min = df['low'].rolling(\n",
    "            min_periods=1, window=n_days, center=False).min()\n",
    "        high_max = df['high'].rolling(\n",
    "            min_periods=1, window=n_days, center=False).max()\n",
    "\n",
    "        cv = (df['close'] - low_min) / (high_max - low_min)\n",
    "        df[column_name] = cv.fillna(0).astype('float64') * 100\n",
    "\n",
    "    @staticmethod\n",
    "    def _positive_sum(data):\n",
    "        data = [i if i > 0 else 0 for i in data]\n",
    "        ret = data[0]\n",
    "        for i in data[1:]:\n",
    "            ret = (ret * (len(data) - 1) + i) / len(data)\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def _negative_sum(data):\n",
    "        data = [-i if i < 0 else 0 for i in data]\n",
    "        ret = data[0]\n",
    "        for i in data[1:]:\n",
    "            ret = (ret * (len(data) - 1) + i) / len(data)\n",
    "        return ret\n",
    "\n",
    "    # noinspection PyUnresolvedReferences\n",
    "    @classmethod\n",
    "    def _get_rsi(cls, df, n_days):\n",
    "        \"\"\" Calculate the RSI (Relative Strength Index) within N days\n",
    "\n",
    "        calculated based on the formula at:\n",
    "        https://en.wikipedia.org/wiki/Relative_strength_index\n",
    "\n",
    "        :param df: data\n",
    "        :param n_days: N days\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        n_days = int(n_days)\n",
    "        d = df['close_-1_d']\n",
    "\n",
    "        df['closepm'] = (d + d.abs()) / 2\n",
    "        df['closenm'] = (-d + d.abs()) / 2\n",
    "        closepm_smma_column = 'closepm_{}_smma'.format(n_days)\n",
    "        closenm_smma_column = 'closenm_{}_smma'.format(n_days)\n",
    "        p_ema = df[closepm_smma_column]\n",
    "        n_ema = df[closenm_smma_column]\n",
    "\n",
    "        rs_column_name = 'rs_{}'.format(n_days)\n",
    "        rsi_column_name = 'rsi_{}'.format(n_days)\n",
    "        df[rs_column_name] = rs = p_ema / n_ema\n",
    "        df[rsi_column_name] = 100 - 100 / (1.0 + rs)\n",
    "\n",
    "        del df['closepm']\n",
    "        del df['closenm']\n",
    "        del df[closepm_smma_column]\n",
    "        del df[closenm_smma_column]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_smma(cls, df, column, windows):\n",
    "        \"\"\" get smoothed moving average.\n",
    "\n",
    "        :param df: data\n",
    "        :param windows: range\n",
    "        :return: result series\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = '{}_{}_smma'.format(column, window)\n",
    "        smma = df[column].ewm(\n",
    "            ignore_na=False, alpha=1.0 / window,\n",
    "            min_periods=0, adjust=True).mean()\n",
    "        df[column_name] = smma\n",
    "        return smma\n",
    "\n",
    "    @classmethod\n",
    "    def _get_trix(cls, df, column=None, windows=None):\n",
    "        if column is None and windows is None:\n",
    "            column_name = 'trix'\n",
    "        else:\n",
    "            column_name = '{}_{}_trix'.format(column, windows)\n",
    "\n",
    "        if column is None:\n",
    "            column = 'close'\n",
    "        if windows is None:\n",
    "            windows = 12\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "\n",
    "        single = '{c}_{w}_ema'.format(c=column, w=window)\n",
    "        double = '{c}_{w}_ema_{w}_ema'.format(c=column, w=window)\n",
    "        triple = '{c}_{w}_ema_{w}_ema_{w}_ema'.format(c=column, w=window)\n",
    "        df['ema3'] = df[triple]\n",
    "        prev_ema3 = df['ema3_-1_s']\n",
    "        df[column_name] = (df['ema3'] - prev_ema3) * 100 / prev_ema3\n",
    "\n",
    "        del df[single]\n",
    "        del df[double]\n",
    "        del df[triple]\n",
    "        del df['ema3']\n",
    "        del df['ema3_-1_s']\n",
    "\n",
    "    @classmethod\n",
    "    def _get_wr(cls, df, n_days):\n",
    "        \"\"\" Williams Overbought/Oversold Index\n",
    "\n",
    "        WMS=[(Hn—Ct)/(Hn—Ln)] ×100\n",
    "        Ct - the close price\n",
    "        Hn - N days high\n",
    "        Ln - N days low\n",
    "\n",
    "        :param df: data\n",
    "        :param n_days: N days\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        n_days = int(n_days)\n",
    "        ln = df['low'].rolling(min_periods=1, window=n_days,\n",
    "                               center=False).min()\n",
    "\n",
    "        hn = df['high'].rolling(min_periods=1, window=n_days,\n",
    "                                center=False).max()\n",
    "        column_name = 'wr_{}'.format(n_days)\n",
    "        df[column_name] = (hn - df['close']) / (hn - ln) * 100\n",
    "\n",
    "    @classmethod\n",
    "    def _get_cci(cls, df, n_days=None):\n",
    "        \"\"\" Commodity Channel Index\n",
    "\n",
    "        CCI = (Typical Price  -  20-period SMA of TP) / (.015 x Mean Deviation)\n",
    "        Typical Price (TP) = (High + Low + Close)/3\n",
    "        TP is also implemented as 'middle'.\n",
    "\n",
    "        :param df: data\n",
    "        :param n_days: N days window\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if n_days is None:\n",
    "            n_days = 14\n",
    "            column_name = 'cci'\n",
    "        else:\n",
    "            n_days = int(n_days)\n",
    "            column_name = 'cci_{}'.format(n_days)\n",
    "\n",
    "        tp = df['middle']\n",
    "        tp_sma = df['middle_{}_sma'.format(n_days)]\n",
    "        md = df['middle'].rolling(\n",
    "            min_periods=1, center=False, window=n_days).apply(\n",
    "            lambda x: np.fabs(x - x.mean()).mean())\n",
    "\n",
    "        df[column_name] = (tp - tp_sma) / (.015 * md)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_tr(cls, df):\n",
    "        \"\"\" True Range of the trading\n",
    "\n",
    "        tr = max[(high - low), abs(high - close_prev), abs(low - close_prev)]\n",
    "        :param df: data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        prev_close = df['close_-1_s']\n",
    "        high = df['high']\n",
    "        low = df['low']\n",
    "        c1 = high - low\n",
    "        c2 = np.abs(high - prev_close)\n",
    "        c3 = np.abs(low - prev_close)\n",
    "        df['tr'] = np.max((c1, c2, c3), axis=0)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_atr(cls, df, window=None):\n",
    "        \"\"\" Average True Range\n",
    "\n",
    "        The average true range is an N-day smoothed moving average (SMMA) of\n",
    "        the true range values.  Default to 14 days.\n",
    "        https://en.wikipedia.org/wiki/Average_true_range\n",
    "\n",
    "        :param df: data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        if window is None:\n",
    "            window = 14\n",
    "            column_name = 'atr'\n",
    "        else:\n",
    "            window = int(window)\n",
    "            column_name = 'atr_{}'.format(window)\n",
    "        tr_smma_column = 'tr_{}_smma'.format(window)\n",
    "\n",
    "        df[column_name] = df[tr_smma_column]\n",
    "        del df[tr_smma_column]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_dma(cls, df):\n",
    "        \"\"\" Different of Moving Average\n",
    "\n",
    "        default to 10 and 50.\n",
    "        :param df: data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df['dma'] = df['close_10_sma'] - df['close_50_sma']\n",
    "\n",
    "    @classmethod\n",
    "    def _get_dmi(cls, df):\n",
    "        \"\"\" get the default setting for DMI\n",
    "\n",
    "        including:\n",
    "        +DI: 14 days SMMA of +DM,\n",
    "        -DI: 14 days SMMA of -DM,\n",
    "        DX: based on +DI and -DI\n",
    "        ADX: 6 days SMMA of DX\n",
    "        :param df: data\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        df['pdi'] = cls._get_pdi(df, 14)\n",
    "        df['mdi'] = cls._get_mdi(df, 14)\n",
    "        df['dx'] = cls._get_dx(df, 14)\n",
    "        df['adx'] = df['dx_6_ema']\n",
    "        df['adxr'] = df['adx_6_ema']\n",
    "\n",
    "    @classmethod\n",
    "    def _get_um_dm(cls, df):\n",
    "        \"\"\" Up move and down move\n",
    "\n",
    "        initialize up move and down move\n",
    "        :param df: data\n",
    "        \"\"\"\n",
    "        hd = df['high_delta']\n",
    "        df['um'] = (hd + hd.abs()) / 2\n",
    "        ld = -df['low_delta']\n",
    "        df['dm'] = (ld + ld.abs()) / 2\n",
    "\n",
    "    @classmethod\n",
    "    def _get_pdm(cls, df, windows):\n",
    "        \"\"\" +DM, positive directional moving\n",
    "\n",
    "        If window is not 1, calculate the SMMA of +DM\n",
    "        :param df: data\n",
    "        :param windows: range\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = 'pdm_{}'.format(window)\n",
    "        um, dm = df['um'], df['dm']\n",
    "        df['pdm'] = np.where(um > dm, um, 0)\n",
    "        if window > 1:\n",
    "            pdm = df['pdm_{}_ema'.format(window)]\n",
    "        else:\n",
    "            pdm = df['pdm']\n",
    "        df[column_name] = pdm\n",
    "\n",
    "    @classmethod\n",
    "    def _get_vr(cls, df, windows=None):\n",
    "        if windows is None:\n",
    "            window = 26\n",
    "            column_name = 'vr'\n",
    "        else:\n",
    "            window = cls.get_only_one_positive_int(windows)\n",
    "            column_name = 'vr_{}'.format(window)\n",
    "\n",
    "        df['av'] = np.where(df['change'] > 0, df['volume'], 0)\n",
    "        avs = df['av'].rolling(\n",
    "            min_periods=1, window=window, center=False).sum()\n",
    "\n",
    "        df['bv'] = np.where(df['change'] < 0, df['volume'], 0)\n",
    "        bvs = df['bv'].rolling(\n",
    "            min_periods=1, window=window, center=False).sum()\n",
    "\n",
    "        df['cv'] = np.where(df['change'] == 0, df['volume'], 0)\n",
    "        cvs = df['cv'].rolling(\n",
    "            min_periods=1, window=window, center=False).sum()\n",
    "\n",
    "        df[column_name] = (avs + cvs / 2) / (bvs + cvs / 2) * 100\n",
    "        del df['av']\n",
    "        del df['bv']\n",
    "        del df['cv']\n",
    "\n",
    "    @classmethod\n",
    "    def _get_mdm(cls, df, windows):\n",
    "        \"\"\" -DM, negative directional moving accumulation\n",
    "\n",
    "        If window is not 1, return the SMA of -DM.\n",
    "        :param df: data\n",
    "        :param windows: range\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = 'mdm_{}'.format(window)\n",
    "        um, dm = df['um'], df['dm']\n",
    "        df['mdm'] = np.where(dm > um, dm, 0)\n",
    "        if window > 1:\n",
    "            mdm = df['mdm_{}_ema'.format(window)]\n",
    "        else:\n",
    "            mdm = df['mdm']\n",
    "        df[column_name] = mdm\n",
    "\n",
    "    @classmethod\n",
    "    def _get_pdi(cls, df, windows):\n",
    "        \"\"\" +DI, positive directional moving index\n",
    "\n",
    "        :param df: data\n",
    "        :param windows: range\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        pdm_column = 'pdm_{}'.format(window)\n",
    "        tr_column = 'atr_{}'.format(window)\n",
    "        pdi_column = 'pdi_{}'.format(window)\n",
    "        df[pdi_column] = df[pdm_column] / df[tr_column] * 100\n",
    "        return df[pdi_column]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_mdi(cls, df, windows):\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        mdm_column = 'mdm_{}'.format(window)\n",
    "        tr_column = 'atr_{}'.format(window)\n",
    "        mdi_column = 'mdi_{}'.format(window)\n",
    "        df[mdi_column] = df[mdm_column] / df[tr_column] * 100\n",
    "        return df[mdi_column]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_dx(cls, df, windows):\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        dx_column = 'dx_{}'.format(window)\n",
    "        mdi_column = 'mdi_{}'.format(window)\n",
    "        pdi_column = 'pdi_{}'.format(window)\n",
    "        mdi, pdi = df[mdi_column], df[pdi_column]\n",
    "        df[dx_column] = abs(pdi - mdi) / (pdi + mdi) * 100\n",
    "        return df[dx_column]\n",
    "\n",
    "    @classmethod\n",
    "    def _get_kdj_default(cls, df):\n",
    "        \"\"\" default KDJ, 9 days\n",
    "\n",
    "        :param df: k line data frame\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df['kdjk'] = df['kdjk_9']\n",
    "        df['kdjd'] = df['kdjd_9']\n",
    "        df['kdjj'] = df['kdjj_9']\n",
    "\n",
    "    @classmethod\n",
    "    def _get_cr(cls, df, window=26):\n",
    "        ym = df['middle_-1_s']\n",
    "        h = df['high']\n",
    "        p1_m = df.loc[:, ['middle_-1_s', 'high']].min(axis=1)\n",
    "        p2_m = df.loc[:, ['middle_-1_s', 'low']].min(axis=1)\n",
    "        p1 = (h - p1_m).rolling(\n",
    "            min_periods=1, window=window, center=False).sum()\n",
    "        p2 = (ym - p2_m).rolling(\n",
    "            min_periods=1, window=window, center=False).sum()\n",
    "        df['cr'] = p1 / p2 * 100\n",
    "        del df['middle_-1_s']\n",
    "        df['cr-ma1'] = cls._shifted_cr_sma(df, 5)\n",
    "        df['cr-ma2'] = cls._shifted_cr_sma(df, 10)\n",
    "        df['cr-ma3'] = cls._shifted_cr_sma(df, 20)\n",
    "\n",
    "    @classmethod\n",
    "    def _shifted_cr_sma(cls, df, window):\n",
    "        name = cls._temp_name()\n",
    "        df[name] = df['cr'].rolling(min_periods=1, window=window,\n",
    "                                    center=False).mean()\n",
    "        to_shift = '{}_-{}_s'.format(name, int(window / 2.5 + 1))\n",
    "        ret = df[to_shift]\n",
    "        del df[name], df[to_shift]\n",
    "        return ret\n",
    "\n",
    "    @classmethod\n",
    "    def _temp_name(cls):\n",
    "        return 'sdf{}'.format(random.randint(0, 10e8))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_middle(cls, df):\n",
    "        df['middle'] = (df['close'] + df['high'] + df['low']) / 3.0\n",
    "\n",
    "    @classmethod\n",
    "    def _calc_kd(cls, column):\n",
    "        param0, param1 = cls.KDJ_PARAM\n",
    "        k = 50.0\n",
    "        # noinspection PyTypeChecker\n",
    "        for i in param1 * column:\n",
    "            k = param0 * k + i\n",
    "            yield k\n",
    "\n",
    "    @classmethod\n",
    "    def _get_kdjk(cls, df, n_days):\n",
    "        \"\"\" Get the K of KDJ\n",
    "\n",
    "        K ＝ 2/3 × (prev. K) +1/3 × (curr. RSV)\n",
    "        2/3 and 1/3 are the smooth parameters.\n",
    "        :param df: data\n",
    "        :param n_days: calculation range\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        rsv_column = 'rsv_{}'.format(n_days)\n",
    "        k_column = 'kdjk_{}'.format(n_days)\n",
    "        df[k_column] = list(cls._calc_kd(df.get(rsv_column)))\n",
    "\n",
    "    @classmethod\n",
    "    def _get_kdjd(cls, df, n_days):\n",
    "        \"\"\" Get the D of KDJ\n",
    "\n",
    "        D = 2/3 × (prev. D) +1/3 × (curr. K)\n",
    "        2/3 and 1/3 are the smooth parameters.\n",
    "        :param df: data\n",
    "        :param n_days: calculation range\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        k_column = 'kdjk_{}'.format(n_days)\n",
    "        d_column = 'kdjd_{}'.format(n_days)\n",
    "        df[d_column] = list(cls._calc_kd(df.get(k_column)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_kdjj(df, n_days):\n",
    "        \"\"\" Get the J of KDJ\n",
    "\n",
    "        J = 3K-2D\n",
    "        :param df: data\n",
    "        :param n_days: calculation range\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        k_column = 'kdjk_{}'.format(n_days)\n",
    "        d_column = 'kdjd_{}'.format(n_days)\n",
    "        j_column = 'kdjj_{}'.format(n_days)\n",
    "        df[j_column] = 3 * df[k_column] - 2 * df[d_column]\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_random_nan(pd_obj):\n",
    "        return pd_obj.where((pd.notnull(pd_obj)), None)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_d(df, column, shifts):\n",
    "        shift = StockDataFrame.to_int(shifts)\n",
    "        shift_column = '{}_{}_s'.format(column, shift)\n",
    "        column_name = '{}_{}_d'.format(column, shift)\n",
    "        df[column_name] = df[column] - df[shift_column]\n",
    "        StockDataFrame.set_nan(df[column_name], shift)\n",
    "\n",
    "    @classmethod\n",
    "    def _get_sma(cls, df, column, windows):\n",
    "        \"\"\" get simple moving average\n",
    "\n",
    "        :param df: data\n",
    "        :param column: column to calculate\n",
    "        :param windows: collection of window of simple moving average\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = '{}_{}_sma'.format(column, window)\n",
    "        df[column_name] = df[column].rolling(min_periods=1, window=window,\n",
    "                                             center=False).mean()\n",
    "\n",
    "    @classmethod\n",
    "    def _get_ema(cls, df, column, windows):\n",
    "        \"\"\" get exponential moving average\n",
    "\n",
    "        :param df: data\n",
    "        :param column: column to calculate\n",
    "        :param windows: collection of window of exponential moving average\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = '{}_{}_ema'.format(column, window)\n",
    "        if len(df[column]) > 0:\n",
    "            df[column_name] = df[column].ewm(\n",
    "                ignore_na=False, span=window,\n",
    "                min_periods=0, adjust=True).mean()\n",
    "        else:\n",
    "            df[column_name] = []\n",
    "\n",
    "    @classmethod\n",
    "    def _get_boll(cls, df):\n",
    "        \"\"\" Get Bollinger bands.\n",
    "\n",
    "        boll_ub means the upper band of the Bollinger bands\n",
    "        boll_lb means the lower band of the Bollinger bands\n",
    "        boll_ub = MA + Kσ\n",
    "        boll_lb = MA − Kσ\n",
    "        M = BOLL_PERIOD\n",
    "        K = BOLL_STD_TIMES\n",
    "        :param df: data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        moving_avg = df['close_{}_sma'.format(cls.BOLL_PERIOD)]\n",
    "        moving_std = df['close_{}_mstd'.format(cls.BOLL_PERIOD)]\n",
    "        df['boll'] = moving_avg\n",
    "        moving_avg = list(map(np.float64, moving_avg))\n",
    "        moving_std = list(map(np.float64, moving_std))\n",
    "        # noinspection PyTypeChecker\n",
    "        df['boll_ub'] = np.add(moving_avg,\n",
    "                               np.multiply(cls.BOLL_STD_TIMES, moving_std))\n",
    "        # noinspection PyTypeChecker\n",
    "        df['boll_lb'] = np.subtract(moving_avg,\n",
    "                                    np.multiply(cls.BOLL_STD_TIMES,\n",
    "                                                moving_std))\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_macd(df):\n",
    "        \"\"\" Moving Average Convergence Divergence\n",
    "\n",
    "        This function will initialize all following columns\n",
    "\n",
    "        MACD Line (macd): (12-day EMA - 26-day EMA)\n",
    "        Signal Line (macds): 9-day EMA of MACD Line\n",
    "        MACD Histogram (macdh): MACD Line - Signal Line\n",
    "        :param df: data\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        fast = df['close_12_ema']\n",
    "        slow = df['close_26_ema']\n",
    "        df['macd'] = fast - slow\n",
    "        df['macds'] = df['macd_9_ema']\n",
    "        df['macdh'] = 2 * (df['macd'] - df['macds'])\n",
    "        del df['macd_9_ema']\n",
    "        del fast\n",
    "        del slow\n",
    "\n",
    "    @classmethod\n",
    "    def get_only_one_positive_int(cls, windows):\n",
    "        if isinstance(windows, int):\n",
    "            window = windows\n",
    "        else:\n",
    "            window = cls.to_int(windows)\n",
    "            if window <= 0:\n",
    "                raise IndexError(\"window must be greater than 0\")\n",
    "        return window\n",
    "\n",
    "    @classmethod\n",
    "    def _get_mstd(cls, df, column, windows):\n",
    "        \"\"\" get moving standard deviation\n",
    "\n",
    "        :param df: data\n",
    "        :param column: column to calculate\n",
    "        :param windows: collection of window of moving standard deviation\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = '{}_{}_mstd'.format(column, window)\n",
    "        df[column_name] = df[column].rolling(min_periods=1, window=window,\n",
    "                                             center=False).std()\n",
    "\n",
    "    @classmethod\n",
    "    def _get_mvar(cls, df, column, windows):\n",
    "        \"\"\" get moving variance\n",
    "\n",
    "        :param df: data\n",
    "        :param column: column to calculate\n",
    "        :param windows: collection of window of moving variance\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        window = cls.get_only_one_positive_int(windows)\n",
    "        column_name = '{}_{}_mvar'.format(column, window)\n",
    "        df[column_name] = df[column].rolling(\n",
    "            min_periods=1, window=window, center=False).var()\n",
    "\n",
    "    @staticmethod\n",
    "    def parse_column_name(name):\n",
    "        m = re.match('(.*)_([\\d\\-\\+~,\\.]+)_(\\w+)', name)\n",
    "        ret = [None, None, None]\n",
    "        if m is None:\n",
    "            m = re.match('(.*)_([\\d\\-\\+~,]+)', name)\n",
    "            if m is not None:\n",
    "                ret = m.group(1, 2)\n",
    "                ret = ret + (None,)\n",
    "        else:\n",
    "            ret = m.group(1, 2, 3)\n",
    "        return ret\n",
    "\n",
    "    CROSS_COLUMN_MATCH_STR = '(.+)_(x|xu|xd)_(.+)'\n",
    "\n",
    "    @classmethod\n",
    "    def is_cross_columns(cls, name):\n",
    "        return re.match(cls.CROSS_COLUMN_MATCH_STR, name) is not None\n",
    "\n",
    "    @classmethod\n",
    "    def parse_cross_column(cls, name):\n",
    "        m = re.match(cls.CROSS_COLUMN_MATCH_STR, name)\n",
    "        ret = [None, None, None]\n",
    "        if m is not None:\n",
    "            ret = m.group(1, 2, 3)\n",
    "        return ret\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_rate(df):\n",
    "        \"\"\" same as percent\n",
    "\n",
    "        :param df: data frame\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        df['rate'] = df['close'].pct_change() * 100\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_delta(df, key):\n",
    "        key_to_delta = key.replace('_delta', '')\n",
    "        df[key] = df[key_to_delta].diff()\n",
    "        return df[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_cross(df, key):\n",
    "        left, op, right = StockDataFrame.parse_cross_column(key)\n",
    "        lt_series = df[left] > df[right]\n",
    "        # noinspection PyTypeChecker\n",
    "        different = np.zeros_like(lt_series)\n",
    "        if len(different) > 1:\n",
    "            # noinspection PyTypeChecker\n",
    "            different[1:] = np.diff(lt_series)\n",
    "            different[0] = False\n",
    "        if op == 'x':\n",
    "            df[key] = different\n",
    "        elif op == 'xu':\n",
    "            df[key] = different & lt_series\n",
    "        elif op == 'xd':\n",
    "            df[key] = different & ~lt_series\n",
    "        return df[key]\n",
    "\n",
    "    @staticmethod\n",
    "    def init_columns(obj, columns):\n",
    "        if isinstance(columns, list):\n",
    "            for column in columns:\n",
    "                StockDataFrame.__init_column(obj, column)\n",
    "        else:\n",
    "            StockDataFrame.__init_column(obj, columns)\n",
    "\n",
    "    @classmethod\n",
    "    def __init_not_exist_column(cls, df, key):\n",
    "        if key == 'change':\n",
    "            cls._get_change(df)\n",
    "        elif key == 'rate':\n",
    "            cls._get_rate(df)\n",
    "        elif key == 'middle':\n",
    "            cls._get_middle(df)\n",
    "        elif key in ['boll', 'boll_ub', 'boll_lb']:\n",
    "            cls._get_boll(df)\n",
    "        elif key in ['macd', 'macds', 'macdh']:\n",
    "            cls._get_macd(df)\n",
    "        elif key in ['kdjk', 'kdjd', 'kdjj']:\n",
    "            cls._get_kdj_default(df)\n",
    "        elif key in ['cr', 'cr-ma1', 'cr-ma2', 'cr-ma3']:\n",
    "            cls._get_cr(df)\n",
    "        elif key in ['cci']:\n",
    "            cls._get_cci(df)\n",
    "        elif key in ['tr']:\n",
    "            cls._get_tr(df)\n",
    "        elif key in ['atr']:\n",
    "            cls._get_atr(df)\n",
    "        elif key in ['um', 'dm']:\n",
    "            cls._get_um_dm(df)\n",
    "        elif key in ['pdi', 'mdi', 'dx', 'adx', 'adxr']:\n",
    "            cls._get_dmi(df)\n",
    "        elif key in ['trix']:\n",
    "            cls._get_trix(df)\n",
    "        elif key in ['vr']:\n",
    "            cls._get_vr(df)\n",
    "        elif key in ['dma']:\n",
    "            cls._get_dma(df)\n",
    "        elif key == 'log-ret':\n",
    "            cls._get_log_ret(df)\n",
    "        elif key.endswith('_delta'):\n",
    "            cls._get_delta(df, key)\n",
    "        elif cls.is_cross_columns(key):\n",
    "            cls._get_cross(df, key)\n",
    "        else:\n",
    "            c, r, t = cls.parse_column_name(key)\n",
    "            if t is not None:\n",
    "                if t in cls.OPERATORS:\n",
    "                    # support all kinds of compare operators\n",
    "                    cls._get_op(df, c, r, t)\n",
    "                else:\n",
    "                    func_name = '_get_{}'.format(t)\n",
    "                    getattr(cls, func_name)(df, c, r)\n",
    "            else:\n",
    "                func_name = '_get_{}'.format(c)\n",
    "                getattr(cls, func_name)(df, r)\n",
    "\n",
    "    @staticmethod\n",
    "    def __init_column(df, key):\n",
    "        if key not in df:\n",
    "            if len(df) == 0:\n",
    "                df[key] = []\n",
    "            else:\n",
    "                StockDataFrame.__init_not_exist_column(df, key)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        try:\n",
    "            result = self.retype(\n",
    "                super(StockDataFrame, self).__getitem__(item))\n",
    "        except KeyError:\n",
    "            try:\n",
    "                self.init_columns(self, item)\n",
    "            except AttributeError:\n",
    "                log.exception('{} not found.'.format(item))\n",
    "            result = self.retype(\n",
    "                super(StockDataFrame, self).__getitem__(item))\n",
    "        return result\n",
    "\n",
    "    def in_date_delta(self, delta_day, anchor=None):\n",
    "        if anchor is None:\n",
    "            anchor = self.get_today()\n",
    "        other_day = get_date_from_diff(anchor, delta_day)\n",
    "        if delta_day > 0:\n",
    "            start, end = anchor, other_day\n",
    "        else:\n",
    "            start, end = other_day, anchor\n",
    "        return self.retype(self.ix[start:end])\n",
    "\n",
    "    def till(self, end_date):\n",
    "        return self[self.index <= end_date]\n",
    "\n",
    "    def start_from(self, start_date):\n",
    "        return self[self.index >= start_date]\n",
    "\n",
    "    def within(self, start_date, end_date):\n",
    "        return self.start_from(start_date).till(end_date)\n",
    "\n",
    "    def copy(self, deep=True):\n",
    "        return self.retype(super(StockDataFrame, self).copy(deep))\n",
    "\n",
    "    @staticmethod\n",
    "    def retype(value, index_column=None):\n",
    "        \"\"\" if the input is a `DataFrame`, convert it to this class.\n",
    "\n",
    "        :param index_column: the column that will be used as index,\n",
    "                             default to `date`\n",
    "        :param value: value to convert\n",
    "        :return: this extended class\n",
    "        \"\"\"\n",
    "        if index_column is None:\n",
    "            index_column = 'date'\n",
    "\n",
    "        if isinstance(value, pd.DataFrame):\n",
    "            # use all lower case for column name\n",
    "            value.columns = map(lambda c: c.lower(), value.columns)\n",
    "\n",
    "            if index_column in value.columns:\n",
    "                value.set_index(index_column, inplace=True)\n",
    "            value = StockDataFrame(value)\n",
    "        return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('WIKI_PRICES_212b326a081eacca455e13140d7bb9db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14860480, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthew/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero = data.ix[data['open'] == 0]\n",
    "zero.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['marketopen'] = data['volume'] * data['open']\n",
    "data['marketclose'] = data['volume'] * data['close']\n",
    "data['marketgain'] = data['marketclose'] - data['marketopen']\n",
    "data['volatility'] = (data['high'] - data['low']) / ((data['high'] + data['low']) / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['daily_change'] = data['close'] - data['open']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['dailyrate'] = data['close'] / data['open'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14860480, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def middle_of_term(name):\n",
    "    stock = data.loc[(data['ticker'] ==  name)]\n",
    "    stock['date'] = pd.DatetimeIndex(stock['date'])\n",
    "    stockmiddle = stock.loc[:,('date','open')]\n",
    "    stockmiddle['date'] = pd.DatetimeIndex(stockmiddle['date']) + pd.DateOffset(-45)\n",
    "    stockmiddle['middle price'] = stockmiddle['open']\n",
    "    stockmiddle.set_index('date', drop=False, inplace=True)\n",
    "    stockmiddle.drop('open', 1, inplace=True)\n",
    "    stock.set_index('date', drop=False, inplace=True)\n",
    "    output = pd.merge(stock,stockmiddle, left_on='date', right_on='date')\n",
    "    output.set_index('date', drop=False, inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def middle_of_term2(name,days):\n",
    "    stock = data.loc[(data['ticker'] ==  name)]\n",
    "    stock['date'] = pd.DatetimeIndex(stock['date'])\n",
    "    stockmiddle = stock.loc[:,('date','open')]\n",
    "    stockmiddle['date'] = pd.DatetimeIndex(stockmiddle['date']) + pd.DateOffset(-days)\n",
    "    stockmiddle['middle price'] = stockmiddle['open']\n",
    "    stockmiddle.set_index('date', drop=False, inplace=True)\n",
    "    stockmiddle.drop('open', 1, inplace=True)\n",
    "    stock.set_index('date', drop=False, inplace=True)\n",
    "    output = pd.merge(stock,stockmiddle, left_on='date', right_on='date')\n",
    "    output.set_index('date', drop=False, inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             open  middle price\n",
      "date                           \n",
      "1986-03-14  28.00         33.75\n",
      "1986-03-17  29.00         32.25\n",
      "1986-03-18  29.50         31.75\n",
      "1986-03-21  27.50         31.75\n",
      "1986-03-24  26.75         31.75\n"
     ]
    }
   ],
   "source": [
    "hdstock = data[(data['ticker'] == 'MSFT')][['date','open']]\n",
    "hdstock['date'] = pd.DatetimeIndex(hdstock['date'])\n",
    "hdstockmiddle = hdstock[['date','open']]\n",
    "hdstockmiddle['date'] = pd.DatetimeIndex(hdstockmiddle['date']) + pd.DateOffset(-45)\n",
    "hdstockmiddle['middle price'] = hdstockmiddle['open']\n",
    "hdstockmiddle.set_index('date', drop=False, inplace=True)\n",
    "hdstockmiddle.drop('open', 1, inplace=True)\n",
    "hdstock.set_index('date', drop=False, inplace=True)\n",
    "msft = pd.merge(hdstock,hdstockmiddle, left_on='date', right_on='date')\n",
    "msft.set_index('date', drop=True, inplace=True)\n",
    "print msft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#sample1 = data.sample(n=1000000, random_state = 234)\n",
    "stock = StockDataFrame.retype(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8ebd2d91657c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_2_d'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open_2_d'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma3'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cr-ma3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} not found.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36minit_columns\u001b[0;34m(obj, columns)\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__init_column\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_not_exist_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__init_not_exist_column\u001b[0;34m(cls, df, key)\u001b[0m\n\u001b[1;32m    873\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_kdj_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cr-ma1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cr-ma2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cr-ma3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cci'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m_get_cr\u001b[0;34m(cls, df, window)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_cr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'middle_-1_s'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'high'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mp1_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'middle_-1_s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'high'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 925\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    926\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{} not found.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36minit_columns\u001b[0;34m(obj, columns)\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 858\u001b[0;31m             \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__init_column\u001b[0;34m(df, key)\u001b[0m\n\u001b[1;32m    915\u001b[0m                 \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m                 \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init_not_exist_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m__init_not_exist_column\u001b[0;34m(cls, df, key)\u001b[0m\n\u001b[1;32m    904\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m                     \u001b[0mfunc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_get_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m                     \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0mfunc_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'_get_{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m_get_s\u001b[0;34m(cls, df, column, shifts)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mshifted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{}_{}_s\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshifted_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mshifted_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36mset_nan\u001b[0;34m(pd_obj, shift)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;31m# shift is not iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0mStockDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_nan_of_single_shift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-392831b40b86>\u001b[0m in \u001b[0;36m_set_nan_of_single_shift\u001b[0;34m(pd_obj, shift)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mpd_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mshift\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0mpd_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# check for chained assignment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_chained_assignment_possible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# actually do the set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_check_is_chained_assignment_possible\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_view\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_cached\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m             \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m                 self._check_setitem_copy(stacklevel=4, t='referant',\n\u001b[1;32m   1786\u001b[0m                                          force=True)\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_is_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3173\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3176\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_protect_consolidate\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m   3125\u001b[0m         \"\"\"\n\u001b[1;32m   3126\u001b[0m         \u001b[0mblocks_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3127\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mblocks_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3173\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_mixed_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_protect_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mis_mixed_type\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3310\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_mixed_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3311\u001b[0m         \u001b[0;31m# Warning, consolidation needs to get checked upstairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3312\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_consolidated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3578\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_consolidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3579\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3580\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_consolidate\u001b[0;34m(blocks)\u001b[0m\n\u001b[1;32m   4523\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_can_consolidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_blocks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrouper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4524\u001b[0m         merged_blocks = _merge_blocks(list(group_blocks), dtype=dtype,\n\u001b[0;32m-> 4525\u001b[0;31m                                       _can_consolidate=_can_consolidate)\n\u001b[0m\u001b[1;32m   4526\u001b[0m         \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerged_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4527\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_blocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_merge_blocks\u001b[0;34m(blocks, dtype, _can_consolidate)\u001b[0m\n\u001b[1;32m   4543\u001b[0m         \u001b[0;31m# combination of those slices is a slice, too.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4544\u001b[0m         \u001b[0mnew_mgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4545\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4547\u001b[0m         \u001b[0margsort\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_vstack\u001b[0;34m(to_stack, dtype)\u001b[0m\n\u001b[1;32m   4589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4591\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_stack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/matthew/anaconda2/lib/python2.7/site-packages/numpy/core/shape_base.pyc\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \"\"\"\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_m\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stock['macd'] = stock['macd']\n",
    "stock['volume_delta'] = stock['volume_delta']\n",
    "stock['open_-2_r'] = stock['open_-2_r']\n",
    "stock['open_2_d'] = stock['open_2_d']\n",
    "stock['cr'] = stock['cr']\n",
    "stock['cr-ma1'] = stock['cr-ma1']\n",
    "stock['cr-ma2'] = stock['cr-ma2']\n",
    "stock['cr-ma3'] = stock['cr-ma3']\n",
    "stock['volume_-3,2,-1_max'] = stock['volume_-3,2,-1_max']\n",
    "#stock['volume_-3~1_min'] = stock['volume_-3~1_min']\n",
    "stock['boll'] = stock['boll']\n",
    "stock['boll_ub'] = stock['boll_ub']\n",
    "stock['boll_lb'] = stock['boll_lb']\n",
    "#stock['close_10.0_le_5_c'] = stock['close_10.0_le_5_c']\n",
    "#stock['cr-ma2_xu_cr-ma1_20_c'] = stock['cr-ma2_xu_cr-ma1_20_c']\n",
    "#stock['rsi_6'] = stock['rsi_6']\n",
    "stock['bollstatus'] = (stock['open'] - stock['boll_lb']) / (stock['boll_ub'] - stock['boll_lb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "stock = stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock.to_csv('toram.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "c = stock.corr()\n",
    "s = c.unstack()\n",
    "so = s.order(kind=\"quicksort\")\n",
    "print so['dailyrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "iris = stock[['marketgain', 'volatility','bollstatus','dailyrate','daily_change']]\n",
    "g = sns.pairplot(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "lmplot seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change','dailyrate']\n",
    "#X = stock.drop(dropped, 1)\n",
    "X = stock[['marketgain', 'volatility','bollstatus','daily_change']]\n",
    "y = stock['dailyrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "linreg = LinearRegression().fit(X, y)\n",
    "#logreg = LogisticRegression().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reg_scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "print reg_scores, np.mean(reg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note the difference in argument order\n",
    "# optionally, you can chain \"fit()\" to the model object\n",
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - $\\hat{y}$\")\n",
    "plt.ylabel(\"Actual Values - $y$\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# High volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highvolume = data.loc[data['volume'] > 6981000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "highvolume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock = StockDataFrame.retype(highvolume)\n",
    "stock['macd'] = stock['macd']\n",
    "stock['volume_delta'] = stock['volume_delta']\n",
    "stock['open_-2_r'] = stock['open_-2_r']\n",
    "stock['open_2_d'] = stock['open_2_d']\n",
    "stock['cr'] = stock['cr']\n",
    "stock['cr-ma1'] = stock['cr-ma1']\n",
    "stock['cr-ma2'] = stock['cr-ma2']\n",
    "stock['cr-ma3'] = stock['cr-ma3']\n",
    "stock['volume_-3,2,-1_max'] = stock['volume_-3,2,-1_max']\n",
    "stock['boll'] = stock['boll']\n",
    "stock['boll_ub'] = stock['boll_ub']\n",
    "stock['boll_lb'] = stock['boll_lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock = stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change','dailyrate']\n",
    "X = stock.drop(dropped, 1)\n",
    "y = stock['dailyrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "names = X.dtypes.index\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock.to_csv('toram.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Daily Rate\")\n",
    "plt.ylabel(\"Actual Values - Daily Rate\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_large = stock[['volatility','marketgain','marketopen','marketclose']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X_large)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X_large)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - $\\hat{y}$\")\n",
    "plt.ylabel(\"Actual Values - $y$\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     X, y, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xr = X\n",
    "yr = y\n",
    "\n",
    "#Xc = admit[['gpa','gre','prestige']]\n",
    "#yc = admit.admit.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reg_scores = cross_val_score(LinearRegression(), Xr, yr, cv=4)\n",
    "#cls_scores = cross_val_score(LogisticRegression(), Xc, yc, cv=4)\n",
    "\n",
    "print reg_scores, np.mean(reg_scores)\n",
    "#print cls_scores, np.mean(cls_scores)\n",
    "\n",
    "linreg = LinearRegression().fit(Xr, yr)\n",
    "#logreg = LogisticRegression().fit(Xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dtr1 = DecisionTreeRegressor(max_depth=1)\n",
    "dtr2 = DecisionTreeRegressor(max_depth=2)\n",
    "dtr3 = DecisionTreeRegressor(max_depth=3)\n",
    "dtr10 = DecisionTreeRegressor(max_depth=10)\n",
    "dtrN = DecisionTreeRegressor(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dtr1.fit(Xr, yr)\n",
    "dtr2.fit(Xr, yr)\n",
    "dtr3.fit(Xr, yr)\n",
    "dtr10.fit(Xr, yr)\n",
    "dtrN.fit(Xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dtr1_scores = cross_val_score(dtr1, Xr, yr, cv=4)\n",
    "dtr2_scores = cross_val_score(dtr2, Xr, yr, cv=4)\n",
    "dtr3_scores = cross_val_score(dtr3, Xr, yr, cv=4)\n",
    "dtr10_scores = cross_val_score(dtr10, Xr, yr, cv=4)\n",
    "dtrN_scores = cross_val_score(dtrN, Xr, yr, cv=4)\n",
    "\n",
    "print dtr1_scores, np.mean(dtr1_scores)\n",
    "print dtr2_scores, np.mean(dtr2_scores)\n",
    "print dtr3_scores, np.mean(dtr3_scores)\n",
    "print dtr10_scores, np.mean(dtr10_scores)\n",
    "print dtrN_scores, np.mean(dtrN_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Set up some text data as well to predict performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Small Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "smallvolume = data.loc[data['volume'] < 3670]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock = StockDataFrame.retype(smallvolume)\n",
    "stock['macd'] = stock['macd']\n",
    "stock['volume_delta'] = stock['volume_delta']\n",
    "stock['open_-2_r'] = stock['open_-2_r']\n",
    "stock['open_2_d'] = stock['open_2_d']\n",
    "stock['cr'] = stock['cr']\n",
    "stock['cr-ma1'] = stock['cr-ma1']\n",
    "stock['cr-ma2'] = stock['cr-ma2']\n",
    "stock['cr-ma3'] = stock['cr-ma3']\n",
    "stock['volume_-3,2,-1_max'] = stock['volume_-3,2,-1_max']\n",
    "stock['boll'] = stock['boll']\n",
    "stock['boll_ub'] = stock['boll_ub']\n",
    "stock['boll_lb'] = stock['boll_lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock = stock.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change','dailyrate']\n",
    "X = stock.drop(dropped, 1)\n",
    "y = stock['dailyrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"X shape: \"\n",
    "print X.shape\n",
    "print \"y shape: \"\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "names = X.dtypes.index\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Daily Rate\")\n",
    "plt.ylabel(\"Actual Values - Daily Rate\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "small_drop = ['close_12_ema', 'close_26_ema','macd','macds','macdh','cr','cr-ma1','cr-ma2','cr-ma3','close_20_sma','close_20_mstd','boll','boll_ub','boll_lb']\n",
    "X.drop(small_drop, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Daily Rate\")\n",
    "plt.ylabel(\"Actual Values - Daily Rate\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change']\n",
    "X = stock.drop(dropped, 1)\n",
    "y = stock['volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Daily Rate\")\n",
    "plt.ylabel(\"Actual Values - Daily Rate\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Stocks - Daily Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock = StockDataFrame.retype(highvolume)\n",
    "stock['macd'] = stock['macd']\n",
    "stock['volume_delta'] = stock['volume_delta']\n",
    "stock['open_-2_r'] = stock['open_-2_r']\n",
    "stock['open_2_d'] = stock['open_2_d']\n",
    "stock['cr'] = stock['cr']\n",
    "stock['cr-ma1'] = stock['cr-ma1']\n",
    "stock['cr-ma2'] = stock['cr-ma2']\n",
    "stock['cr-ma3'] = stock['cr-ma3']\n",
    "stock['volume_-3,2,-1_max'] = stock['volume_-3,2,-1_max']\n",
    "stock['boll'] = stock['boll']\n",
    "stock['boll_ub'] = stock['boll_ub']\n",
    "stock['boll_lb'] = stock['boll_lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stock = stock.dropna()\n",
    "stock.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change','volatility']\n",
    "X = stock.drop(dropped, 1)\n",
    "y = stock['volatility']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "names = X.dtypes.index\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Volatility\")\n",
    "plt.ylabel(\"Actual Values - Volatility\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dropped = ['ticker','open','close','high','low','adj_open','adj_high','adj_low','adj_close','daily_change','dailyrate']\n",
    "X = stock.drop(dropped, 1)\n",
    "y = stock['dailyrate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Stocks - Daily Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "names = X.dtypes.index\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - Daily Rate\")\n",
    "plt.ylabel(\"Actual Values - Daily Rate\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Restaurant Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chipotlestock = data[data['ticker'] == 'CMG']\n",
    "chipotlestock = StockDataFrame.retype(chipotlestock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numbers = pd.read_csv('2017q1/num.txt',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = pd.read_csv('2017q1/sub.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = name.merge(numbers, left_on = 'adsh', right_on = 'adsh', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "name.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numbers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.drop(dataframe[['countryba','cityba','zipba','bas1','bas2','baph','countryma','sic','stprba','stprma','cityma','zipma','mas1','mas2','countryinc','stprinc','ein','former','changed','afs','wksi','fye','form','period','fy','fp']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "dataframe['filed'] = pd.to_datetime(dataframe['filed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcdonalds = dataframe[dataframe['name'].str.contains(\"MCDONALDS\")]\n",
    "mcdonalds['name'].value_counts()\n",
    "mcdonaldstrends = pd.read_csv('trendsmcdonalds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wendys = dataframe[dataframe['name'].str.contains(\"WENDYS\")]\n",
    "wendystrends = pd.read_csv('trendswendys.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chipotle = dataframe[dataframe['name'].str.contains(\"CHIPOTLE\")]\n",
    "chipotletrends = pd.read_csv('trendschipotle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "buffalo = dataframe[dataframe['name'].str.contains(\"BUFFALO\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yum = dataframe[dataframe['name'].str.contains(\"YUM \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "darden = dataframe[dataframe['name'].str.contains(\"DARDEN\")]\n",
    "dardentrends = pd.read_csv('darden_trends.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dominos = dataframe[dataframe['name'].str.contains(\"DOMINOS\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dunkin = dataframe[dataframe['name'].str.contains(\"DUNKIN\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crackerbarrel = dataframe[dataframe['name'].str.contains(\"CRACKER\")]\n",
    "crackerbarrel['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texasroadhouse = dataframe[dataframe['name'].str.contains(\"TEXAS ROADHOUSE\")]\n",
    "texasroadhouse['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jackinthebox = dataframe[dataframe['name'].str.contains(\"JACK IN\")]\n",
    "jackinthebox['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "performancefood = dataframe[dataframe['name'].str.contains(\"PERFORMANCE FOOD\")]\n",
    "performancefood['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "daveandbuster = dataframe[dataframe['name'].str.contains(\"DAVE &\")]\n",
    "daveandbuster['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cheesecake = dataframe[dataframe['name'].str.contains(\"CHEESECAKE\")]\n",
    "cheesecake['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "buffalo = dataframe[dataframe['name'].str.contains(\"BUFFALO WILD\")]\n",
    "buffalo['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bloomin = dataframe[dataframe['name'].str.contains(\"BLOOMIN\")]\n",
    "bloomin['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "brinker = dataframe[dataframe['name'].str.contains(\"BRINKER\")]\n",
    "brinker['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data2016 = data.ix('date' > 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#chipotlestock = data.ix['2017-01-01':'2017-05-01']\n",
    "month = ['01','04','07','10']\n",
    "years = range(1999, 2017)\n",
    "beginning_of_quarter = []\n",
    "for i in years:\n",
    "    for x in month:\n",
    "        beginning_of_quarter.append(str(i) + '-' + x + '-01')\n",
    "        \n",
    "quarterly = data[data['date'].isin(beginning_of_quarter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chipotlestock = data[(data['ticker'] == 'CMG')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wendystock = data[(data['ticker'] == 'WEN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yumstock = data[(data['ticker'] == 'YUM')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dristock = data[(data['ticker'] == 'DRI')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mcdstock = data[(data['ticker'] == 'MCD')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wendyquarterly = pd.read_csv('WEN_quarterly_financial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yumquarterly = pd.read_csv('YUM_quarterly_financial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driquarterly = pd.read_csv('DRI_quarterly_financial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmgquarterly = pd.read_csv('CMG_quarterly_financial_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wendyquarterly['Quarter end'] = pd.to_datetime(wendyquarterly['Quarter end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wendys = pd.merge(wendyquarterly,wendystock, left_on='Quarter end', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yum_brands = pd.merge(yumquarterly,yumstock, left_on='Quarter end', right_on='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yumquarterly['Quarter end'] = pd.DatetimeIndex(yumquarterly['Quarter end']) + pd.DateOffset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yum_brands = pd.merge(yumquarterly,yumstock, left_on='Quarter end', right_on='date')\n",
    "yum_brands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wendyquarterly['Quarter end'] = pd.DatetimeIndex(wendyquarterly['Quarter end']) + pd.DateOffset(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wendys = pd.merge(wendyquarterly,wendystock, left_on='Quarter end', right_on='date')\n",
    "wendys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driquarterly['Quarter end'] = pd.DatetimeIndex(driquarterly['Quarter end']) + pd.DateOffset(2)\n",
    "dri = pd.merge(driquarterly,dristock, left_on='Quarter end', right_on='date')\n",
    "dri.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mcdquarterly = pd.read_csv('MCD_quarterly_financial_data.csv')\n",
    "mcdquarterly['Quarter end'] = pd.DatetimeIndex(mcdquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "mcd = pd.merge(mcdquarterly,mcdstock, left_on='Quarter end', right_on='date')\n",
    "print mcd.shape\n",
    "print mcdquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def middle_of_term(name):\n",
    "    stock = data.loc[(data['ticker'] ==  name)]\n",
    "    stock['date'] = pd.DatetimeIndex(stock['date'])\n",
    "    stockmiddle = stock.loc[:,('date','open')]\n",
    "    stockmiddle['date'] = pd.DatetimeIndex(stockmiddle['date']) + pd.DateOffset(-45)\n",
    "    stockmiddle['middle price'] = stockmiddle['open']\n",
    "    stockmiddle.set_index('date', drop=False, inplace=True)\n",
    "    stockmiddle.drop('open', 1, inplace=True)\n",
    "    stock.set_index('date', drop=False, inplace=True)\n",
    "    output = pd.merge(stock,stockmiddle, left_on='date', right_on='date')\n",
    "    output.set_index('date', drop=False, inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def middle_of_term2(name,days):\n",
    "    stock = data.loc[(data['ticker'] ==  name)]\n",
    "    stock['date'] = pd.DatetimeIndex(stock['date'])\n",
    "    stockmiddle = stock.loc[:,('date','open')]\n",
    "    stockmiddle['date'] = pd.DatetimeIndex(stockmiddle['date']) + pd.DateOffset(-days)\n",
    "    stockmiddle['middle price'] = stockmiddle['open']\n",
    "    stockmiddle.set_index('date', drop=False, inplace=True)\n",
    "    stockmiddle.drop('open', 1, inplace=True)\n",
    "    stock.set_index('date', drop=False, inplace=True)\n",
    "    output = pd.merge(stock,stockmiddle, left_on='date', right_on='date')\n",
    "    output.set_index('date', drop=False, inplace=True)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "hdstock = data[(data['ticker'] == 'MSFT')][['date','open']]\n",
    "hdstock['date'] = pd.DatetimeIndex(hdstock['date'])\n",
    "hdstockmiddle = hdstock[['date','open']]\n",
    "hdstockmiddle['date'] = pd.DatetimeIndex(hdstockmiddle['date']) + pd.DateOffset(-45)\n",
    "hdstockmiddle['middle price'] = hdstockmiddle['open']\n",
    "hdstockmiddle.set_index('date', drop=False, inplace=True)\n",
    "hdstockmiddle.drop('open', 1, inplace=True)\n",
    "hdstock.set_index('date', drop=False, inplace=True)\n",
    "msft = pd.merge(hdstock,hdstockmiddle, left_on='date', right_on='date')\n",
    "msft.set_index('date', drop=True, inplace=True)\n",
    "print msft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Home Depot\n",
    "hd = middle_of_term2('HD',48)\n",
    "hdquarterly = pd.read_csv('HD_quarterly_financial_data.csv')\n",
    "hdquarterly['Quarter end'] = pd.DatetimeIndex(hdquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "hd = pd.merge(hdquarterly,hd, left_on='Quarter end', right_on='date')\n",
    "print hd.shape\n",
    "print hdquarterly.shape\n",
    "hd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Lowe's\n",
    "low = middle_of_term('LOW')\n",
    "lowquarterly = pd.read_csv('LOW_quarterly_financial_data.csv')\n",
    "lowquarterly['Quarter end'] = pd.DatetimeIndex(lowquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "low = pd.merge(lowquarterly,low, left_on='Quarter end', right_on='date')\n",
    "print low.shape\n",
    "print lowquarterly.shape\n",
    "low.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Sears\n",
    "shld = middle_of_term('SHLD')\n",
    "SHLDquarterly = pd.read_csv('SHLD_quarterly_financial_data.csv')\n",
    "SHLDquarterly['Quarter end'] = pd.DatetimeIndex(SHLDquarterly['Quarter end']) + pd.DateOffset(2)\n",
    "SHLD = pd.merge(SHLDquarterly,shld, left_on='Quarter end', right_on='date')\n",
    "print SHLD.shape\n",
    "print SHLDquarterly.shape\n",
    "print SHLD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### JC Penny\n",
    "jcp = middle_of_term2('JCP',47)\n",
    "JCPquarterly = pd.read_csv('JCP_quarterly_financial_data.csv')\n",
    "JCPquarterly['Quarter end'] = pd.DatetimeIndex(JCPquarterly['Quarter end']) + pd.DateOffset(4)\n",
    "JCP = pd.merge(JCPquarterly,jcp, left_on='Quarter end', right_on='date')\n",
    "print JCP.shape\n",
    "print JCPquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Dillard's\n",
    "dds = middle_of_term('DDS')\n",
    "DDSquarterly = pd.read_csv('DDS_quarterly_financial_data.csv')\n",
    "DDSquarterly['Quarter end'] = pd.DatetimeIndex(DDSquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "DDS = pd.merge(DDSquarterly,dds, left_on='Quarter end', right_on='date')\n",
    "print DDS.shape\n",
    "print DDSquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Kohl's\n",
    "kss = middle_of_term('KSS')\n",
    "KSSquarterly = pd.read_csv('KSS_quarterly_financial_data.csv')\n",
    "KSSquarterly['Quarter end'] = pd.DatetimeIndex(KSSquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "KSS = pd.merge(KSSquarterly,kss, left_on='Quarter end', right_on='date')\n",
    "print KSS.shape\n",
    "print KSSquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Macy's\n",
    "Mstock = middle_of_term('M')\n",
    "Mquarterly = pd.read_csv('M_quarterly_financial_data.csv')\n",
    "Mquarterly['Quarter end'] = pd.DatetimeIndex(Mquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "M = pd.merge(Mquarterly,Mstock, left_on='Quarter end', right_on='date')\n",
    "print M.shape\n",
    "print Mquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TJX\n",
    "TJX = middle_of_term('TJX')\n",
    "TJXquarterly = pd.read_csv('TJX_quarterly_financial_data.csv')\n",
    "TJXquarterly['Quarter end'] = pd.DatetimeIndex(TJXquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "TJX = pd.merge(TJXquarterly,TJX, left_on='Quarter end', right_on='date')\n",
    "print TJX.shape\n",
    "print TJXquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Dollar Tree\n",
    "DLTR = middle_of_term2('DLTR',43)\n",
    "DLTRquarterly = pd.read_csv('DLTR_quarterly_financial_data.csv')\n",
    "DLTRstock = data[(data['ticker'] == 'DLTR')]\n",
    "DLTRquarterly['Quarter end'] = pd.DatetimeIndex(DLTRquarterly['Quarter end']) + pd.DateOffset(2)\n",
    "DLTR = pd.merge(DLTRquarterly,DLTR, left_on='Quarter end', right_on='date')\n",
    "print DLTR.shape\n",
    "print DLTRquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Dollar General\n",
    "DG = middle_of_term('DG')\n",
    "DGquarterly = pd.read_csv('DG_1_quarterly_financial_data.csv')\n",
    "DGstock = data[(data['ticker'] == 'DG')]\n",
    "DGquarterly['Quarter end'] = pd.DatetimeIndex(DGquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "DG = pd.merge(DGquarterly,DGstock, left_on='Quarter end', right_on='date')\n",
    "print DG.shape\n",
    "print DGquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Target\n",
    "TGT = middle_of_term('TGT')\n",
    "TGTquarterly = pd.read_csv('TGT_quarterly_financial_data.csv')\n",
    "TGTquarterly['Quarter end'] = pd.DatetimeIndex(TGTquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "TGT = pd.merge(TGTquarterly,TGT, left_on='Quarter end', right_on='date')\n",
    "print TGT.shape\n",
    "print TGTquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Costco\n",
    "COST = middle_of_term2('COST',47)\n",
    "COSTquarterly = pd.read_csv('COST_quarterly_financial_data.csv')\n",
    "COSTquarterly['Quarter end'] = pd.DatetimeIndex(COSTquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "COST = pd.merge(COSTquarterly,COST, left_on='Quarter end', right_on='date')\n",
    "print COST.shape\n",
    "print COSTquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Wal-Mart\n",
    "wmt = middle_of_term2('WMT',43)\n",
    "WMTquarterly = pd.read_csv('WMT_quarterly_financial_data.csv')\n",
    "WMTquarterly['Quarter end'] = pd.DatetimeIndex(WMTquarterly['Quarter end']) + pd.DateOffset(4)\n",
    "WMT = pd.merge(WMTquarterly,wmt, left_on='Quarter end', right_on='date')\n",
    "print WMT.shape\n",
    "print WMTquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YUM\n",
    "yum = middle_of_term2('YUM',43)\n",
    "YUMquarterly = pd.read_csv('YUM_quarterly_financial_data.csv')\n",
    "YUMquarterly['Quarter end'] = pd.DatetimeIndex(YUMquarterly['Quarter end']) + pd.DateOffset(4)\n",
    "YUM = pd.merge(YUMquarterly,wmt, left_on='Quarter end', right_on='date')\n",
    "print YUM.shape\n",
    "print WMTquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Wendy's\n",
    "WEN = middle_of_term2('WEN',43)\n",
    "WENquarterly = pd.read_csv('WMT_quarterly_financial_data.csv')\n",
    "WENquarterly['Quarter end'] = pd.DatetimeIndex(WENquarterly['Quarter end']) + pd.DateOffset(5)\n",
    "WEN = pd.merge(WENquarterly,WEN, left_on='Quarter end', right_on='date')\n",
    "print WEN.shape\n",
    "print WENquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Darden Restaurants\n",
    "dri = middle_of_term2('DRI',43)\n",
    "DRIquarterly = pd.read_csv('DRI_quarterly_financial_data.csv')\n",
    "DRIquarterly['Quarter end'] = pd.DatetimeIndex(DRIquarterly['Quarter end']) + pd.DateOffset(4)\n",
    "DRI = pd.merge(DRIquarterly,dri, left_on='Quarter end', right_on='date')\n",
    "print DRI.shape\n",
    "print DRIquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### McDonald's\n",
    "mcd = middle_of_term2('MCD',44)\n",
    "MCDquarterly = pd.read_csv('MCD_quarterly_financial_data.csv')\n",
    "MCDquarterly['Quarter end'] = pd.DatetimeIndex(MCDquarterly['Quarter end']) + pd.DateOffset(3)\n",
    "MCD = pd.merge(MCDquarterly,mcd, left_on='Quarter end', right_on='date')\n",
    "print MCD.shape\n",
    "print MCDquarterly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WMT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailers = pd.concat([COST, WMT,TGT,DG,DLTR,TJX,M,KSS,DDS,JCP,SHLD,low,hd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailers[['open','middle price']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "restaurant = pd.concat([YUM,WEN,DRI,MCD])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurant.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "restaurant['half quarter gain'] = restaurant['middle price'] / restaurant['open'] - 1\n",
    "retailers['half quarter gain'] = retailers['middle price'] / retailers['open'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "restaurant.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retailers.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest = pd.concat([retailers, restaurant])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retailrest['half quarter gain'] = retailrest['middle price'] / retailrest['open'] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retailrest.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock = StockDataFrame.retype(retailrest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock['macd'] = stock['macd']\n",
    "stock['volume_delta'] = stock['volume_delta']\n",
    "stock['open_-2_r'] = stock['open_-2_r']\n",
    "stock['open_2_d'] = stock['open_2_d']\n",
    "stock['cr'] = stock['cr']\n",
    "stock['cr-ma1'] = stock['cr-ma1']\n",
    "stock['cr-ma2'] = stock['cr-ma2']\n",
    "stock['cr-ma3'] = stock['cr-ma3']\n",
    "stock['volume_-3,2,-1_max'] = stock['volume_-3,2,-1_max']\n",
    "#stock['volume_-3~1_min'] = stock['volume_-3~1_min']\n",
    "stock['boll'] = stock['boll']\n",
    "stock['boll_ub'] = stock['boll_ub']\n",
    "stock['boll_lb'] = stock['boll_lb']\n",
    "#stock['close_10.0_le_5_c'] = stock['close_10.0_le_5_c']\n",
    "#stock['cr-ma2_xu_cr-ma1_20_c'] = stock['cr-ma2_xu_cr-ma1_20_c']\n",
    "#stock['rsi_6'] = stock['rsi_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retailrest = retailrest.dropna()\n",
    "retailrest = retailrest.drop(['quarter end'], 1)\n",
    "retailrest = retailrest.drop(['asset turnover'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest = retailrest.convert_objects(convert_numeric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "retailrest = retailrest.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = retailrest.drop(['half quarter gain','ticker','middle price'], 1)\n",
    "y = retailrest['half quarter gain']\n",
    "#reg_scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "#print reg_scores, np.mean(reg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Note the difference in argument order\n",
    "# optionally, you can chain \"fit()\" to the model object\n",
    "X = X[['cr-ma1','ex-dividend','split_ratio','close_20_sma','cr','marketopen','middle','macds','close_20_mstd']]\n",
    "y = y[['cr-ma1','ex-dividend','split_ratio','close_20_sma','cr','marketopen','middle','macds','close_20_mstd']]\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X)\n",
    "\n",
    "# Plot the model\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(predictions, y, s=30, c='r', marker='+', zorder=10)\n",
    "plt.xlabel(\"Predicted Values - $\\hat{y}$\")\n",
    "plt.ylabel(\"Actual Values - $y$\")\n",
    "plt.show()\n",
    "\n",
    "print \"MSE:\", mean_squared_error(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "Xr = X\n",
    "yr = y\n",
    "\n",
    "#Xc = admit[['gpa','gre','prestige']]\n",
    "#yc = admit.admit.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "reg_scores = cross_val_score(LinearRegression(), Xr, yr, cv=4)\n",
    "#cls_scores = cross_val_score(LogisticRegression(), Xc, yc, cv=4)\n",
    "\n",
    "print reg_scores, np.mean(reg_scores)\n",
    "#print cls_scores, np.mean(cls_scores)\n",
    "\n",
    "linreg = LinearRegression().fit(Xr, yr)\n",
    "#logreg = LogisticRegression().fit(Xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dtr1 = DecisionTreeRegressor(max_depth=1)\n",
    "dtr2 = DecisionTreeRegressor(max_depth=2)\n",
    "dtr3 = DecisionTreeRegressor(max_depth=3)\n",
    "dtrN = DecisionTreeRegressor(max_depth=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "dtr1.fit(Xr, yr)\n",
    "dtr2.fit(Xr, yr)\n",
    "dtr3.fit(Xr, yr)\n",
    "dtrN.fit(Xr, yr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dtr1_scores = cross_val_score(dtr1, Xr, yr, cv=4)\n",
    "dtr2_scores = cross_val_score(dtr2, Xr, yr, cv=4)\n",
    "dtr3_scores = cross_val_score(dtr3, Xr, yr, cv=4)\n",
    "dtrN_scores = cross_val_score(dtrN, Xr, yr, cv=4)\n",
    "\n",
    "print dtr1_scores, np.mean(dtr1_scores)\n",
    "print dtr2_scores, np.mean(dtr2_scores)\n",
    "print dtr3_scores, np.mean(dtr3_scores)\n",
    "print dtrN_scores, np.mean(dtrN_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = retailers.drop(['half quarter gain','ticker','middle price'], 1)\n",
    "y = retailers['half quarter gain']\n",
    "#reg_scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "#print reg_scores, np.mean(reg_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X, y)\n",
    "print \"Features sorted by their score:\"\n",
    "print sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), names), \n",
    "             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "google trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Google trends data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
